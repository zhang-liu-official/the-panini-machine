---
description: Excerpts from an interesting paper from Saroja Bhate and Subhash Kak (1993)
---

# Pāṇinī's Grammar and Computer Science

## Introduction

The enterprise of computer science has two fundamental elements. The first element is to develop techniques that make the elucidation of the computational structure of nature and the mind easier. The second element is the creation of new computing algorithms and machines that have powerful cognitive and computational abilities: this includes development of new techniques of representing and manipulating knowledge, inference and deduction.

The tasks of representing and processing knowledge with a somewhat different emphasis has parallels in many ancient disciplines. Thus grammarians have long considered questions of relating facts about the physical world and cognition to linguistic expressions. Likewise logicians have developed formal structures to relate events and draw inferences from them. This is seen best in the work of ancient Indian logicians and grammarians. It has been argued by Ingalls, Staal, Matilal, Briggs, Kak and others that many contemporary developments in formal logic, linguistics, and computer science are a rediscovery of the work of these ancient masters. But apart from the question of a correct history of ideas it raises the following important question of significance to Sanskritists as well as cognitive and computer scientists: Are there other rules in ancient Indian logic and grammar that may be of use in making further advance in cognitive and computer sciences? A little bit of history shows why this is a valid question. Nineteenth century Western linguists did not see the significance of the context-sensitive rules of Pāṇinī's grammar. In fact their fundamental importance was seen only when Pāṇinīan style structures were first introduced by Western linguists such as Chomsky about thirty years ago. According to the distinguished linguist Frits Staal: "We can now assert, with the power of hindsight, that Indian linguists in the fifth century B.C. knew and understood more than Western linguists in the nineteenth century A.D. Can one not extend this conclusion and claim that it is probable that Indian linguists are still ahead of their Western colleagues and may continue to be so in the next century? Quite possible; all we can say is that it is difficult to detect something that we have not already discovered ourselves."

Computationally, grammars of natural language are as powerful as any computing machine. But since the setting of a grammar is so different from the typical purpose of a computer, this fact is often obscured. The formal structure of a grammar can be easily adapted so as to perform numerical processing. In this paper we discuss formal aspects of certain rules of Pāṇinī's grammar, Aṣṭādhyāyī \(A\), which is traditionally studied together with the dhātupāṭha, which is a list of verbal roots arranged into sublists, and the gaṇapāṭha, which is a list of various classes of morphs, one class being the dhātupāṭha. It is now becoming clear that A does not merely deal with analysis of words \(śabdānuśāsana\) but in fact provides a structure for the analysis of sentences. Due to its algebraic nature and its comprehensiveness, the structure has been described as a machine generating words and sentences of Sanskrit. Composed in the succinct sūtra style, A consists of nearly 4000 sūtras that capture the fundamentals of Sanskrit language in terms of its phonology, morphology and syntax. As in any formal system, the structure consists of definitions, theorems \(linguistic facts\), and meta-theorems \(rules regarding rules\). The rules are of different kinds: some are universal and context-sensitive transformations, others operate sequentially or recursively. Generally these rules are expressed in three groups: 

1. rules of interpretation or meta-rules: saṃjñā and paribhaāṣā rules,
2. rules of affixation: rules prescribing affixes after two kinds of basic dhātu and prātipadika roots, 
3.  rules of transformation for the stems and the suffixes: the morphophonemic rules. 

Note that a computer program has exactly the same general features of context-sensitive rules, recursion, and sequential rule application. It is not surprising, therefore, that these sūtras have been compared to a computer program that generates Sanskrit sentences. Pāṇinī's grammar is algebraic where a finite set of rules generates an in finite number of words and sentences. 

It is generally agreed that the Pāṇinīan system is based on a principle of economy, an Occam's razor. This makes the structure to be of special interest to cognitive scientists. Furthermore, development of logic has been seen as emerging from the background of grammatical categories both in India and Greece. Considering the preeminent position of the Pāṇinīan system in the Indian intellectual tradition, its significance for students of logic and history of science becomes clear.

It is also important to place Pāṇinī's grammar in the context of a continuing development of mathematics and science in India. Seidenberg has shown that the rise of the earliest mathematics should be seen in the Vedic literature. Furthermore, Kak has established that the Brahmi script of Pāṇinī's time is to be derived from the Indus script of the third millennium B.C. This means that Pāṇinī himself was heir to a very long and rich tradition of learning.

Grammatical categories serve to express knowledge about the world. Pāṇinī's system of knowledge representation is based in the kāraka theory. The kāraka are deep structure relations that mediate mappings from semantic relations \(such as agent, goal, location\) to phonological representations \(in terms of case-endings that may express voices\) via surface structures \(in terms of morphological categories such as nominal cases, prepositions, and verbal voices\). On the morphological level the kārakas are represented by six triplets of case endings, each of which roughly corresponds with one kāraka. The kāraka rules are applied with the governing \(adhikāra\) sūtra P.2.3.1: anabhihite, \(add a case-ending after a lexical unit to convey a kāraka only\) if it is not expressed \(already\). Two of the kārakas, kartṛ and karman can be expressed by verbal endings, whereas some other kārakas can also be expressed by primary and secondary suffixes. The kāraka theory is of obvious interest to the computer scientist interested in natural language processing. The reader interested in the details of this theory should see the essays by Joshi and Kiparsky and Staal.

A comprehensive study of A from a computing science perspective should include linguistic, structural, and algorithmic aspects. Such a study must be based on the long tradition of analysis of A that goes back about 2,500 years. Problems of particular interest to the computer scientist include the arrangement of the rules and the smallest set of rules that would be equivalent to A. Rearranged rules, such as those by Bhaṭṭojī Dīkṣita in his Siddhānta Kaumudī, would provide an invaluable frame of comparison. But before a comparison can be made from an algorithmic perspective one needs to describe A's rule in a form convenient for analysis by computer. With this in mind, we discuss in this introductory paper certain formal aspects of Pāṇinī's grammar. In particular we consider the following two aspects: 

1. The sūtra style and the nature of rules,
2. The structure of the rule system. 

We will show how the rules can be easily cast in familiar algebraic or transformational forms. An explicitly algebraic representation is essential before Pāṇinī's rules are expressed on a computer so that their computational and cognitive implications can be properly assessed.

## Concluding Remarks

Our analysis was meant to highlight several formal features of Pāṇinī's grammar that have direct parallels in computer science. What might be other features of the grammar that have not yet been rediscovered in computer science remains to be seen. But the very success of A suggests that aspects of its structure will have implications for further advance in computer science, knowledge representation, and linguistics. In particular we can hope for significant applications in natural language processing. The ongoing analysis of the structures of Pāṇinī and those of the later grammarians and logicians will be aided by the development of software to implement A on a digital computer. 

The specific issues of immediate interest to the computer scientist include analysis of the arrangement of the rules and search for other arrangements that are equivalent in terms of their generative power. The formal aspects of these arrangements and their relationships is likely to help define the notion of distance between grammars. Such a notion is of immediate relevance for machine translation. Given two languages with grammars that are close in structure, as in the Indo-Aryan family of languages, one would expect the translation across the languages to be relatively easy. A formalization of the notion of closeness is also likely to give pointers regarding how an automatic translation might proceed.

One great virtue of the Pāṇinīan system is that it operates at the level of roots and suffixes defining a deeper level of analysis than afforded by recent approaches like generalized phrase structure grammars that have been inspired by development of computer parsing techniques. This allows for one to include parts of the lexicon in the definition of the grammatical structure. Closeness between languages that share a great deal of a lexicon will thus be represented better using a Pāṇinīan structure. 

These fundamental investigations that have bearing on linguistics, knowledge representation, and natural language processing by computer require collaboration between computer scientists and Sanskritists. Computer oriented studies on A would also help to introduce AI \(artificial intelligence\), logic, and cognitive science as additional areas of study in the Sanskrit departments of universities. This would allow the Sanskrit departments to complement the programme of the computer science departments. With the incorporation of these additional areas, a graduate of Sanskrit could hope to make useful contributions to the computer software industry as well, particularly in the fields of natural language processing and artificial intelligence.



